# Домашнее задание 1:
https://github.com/gyt0308/spbu-deep-learning-course/blob/main/hw1_intro_multimodal_classification.ipynb
1.Выбрать датасет с изображениями (можно MNIST)
2.Выбрать архитектуру нейронной сети, подходящую для вашей конфигурации (лучше всего обучать на GPU компьютера), объяснить выбор. Взять предобученные веса, например, для классификации по ImageNet и дообучить.	
3.Реализовать:
	а) Обучение классификатора на основе выбранной архитектуры
	б) Итеративную аугментацию
	в) Итеративную разморозку слоёв
	г) Адаптивный learning rate
4.Сравнить результаты, например, для таких конфигураций:
	а) Чистый классификатор
	б) Классификатор + итеративная разморозка + адаптивный lr
	в) Классификатор + итеративная аугментация
	г) Классификатор + все методы улучшения
5.Сделать выводы.


# Домашнее задание 2:	
1.Добавить в решение ДЗ 1 псевдолейблинг, сравнить результаты с лучшим из имеющихся классификаторов (можно сделать разделение train-test-val)	
2.Придумать 3 отличающихся от рассказанных на занятии метрики качества поиска (во всем многообразии элементов поисковой выдачи) и объяснить, почему их можно брать в качестве основных для оценки качества. 
3.Придумать 3 отличающихся от рассказанных на занятии метода улучшения качества разметки релевантности и объяснить, как именно они улучшат качество.
4.Рассчитать p-value гипотезы "выдача google по запросу <выберите любой запрос> статистически значимо лучше, чем выдача yandex по этому же запросу". Оценку релевантности всех страниц выдачи, а также уровень значимости (порог, при котором мы отвергаем гипотезу) провести самостоятельно.


# Домашнее задание 3, часть 1 (исправление теста):
	
1.Показать, какие из рассматриваемых метрик (precision, recall, f1, accuracy, roc-auc, pr-auc, specificity, ...) чувствительны к дисбалансу классов на примере бинарной классификации
2.Написать формулу F_beta и объяснить, на что влияет параметр beta, привести примеры, когда beta лучше брать отличным от 1
3.Привести пример расчета ROC-AUC на не менее, чем 6 предсказаниях
4.Провести micro-агрегацию precision и recall, сравнить с взвешенной (на примере)

Домашнее задание 3, часть 2 (по материалам занятия)

1.Применить не менее 5 рассказанных техник оптимизации вашей модели из ДЗ 1 и 2, описать результаты профилирования 
2.Конвертировать модель в OnnxRuntime или TensorRT (+2 доп балла за это) для инференса 	
3.При помощи инференса вашей модели на ваших данных сгенерировать датасет из векторов (размер не менее 1000 векторов)
4.Реализовать product-квантизацию полученного датасета в экстремальном случае: M = D, то есть, каждая компонента вектора квантизуется независимо от других (соответственно, вместо кластеризации простой подбор порогов, при которых ошибка представления компоненты будет наименьшей)
