{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aqeu3kpeHsTr"
      },
      "source": [
        "# псевдомаркировка\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "klIiqwfV-ooD",
        "outputId": "da6428df-0665-4fab-84a6-7a7b54ce50f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "750/750 [==============================] - 390s 517ms/step - loss: 0.5733 - accuracy: 0.8344 - val_loss: 0.3118 - val_accuracy: 0.8985\n",
            "Epoch 2/5\n",
            "750/750 [==============================] - 382s 509ms/step - loss: 0.2540 - accuracy: 0.9246 - val_loss: 0.2057 - val_accuracy: 0.9385\n",
            "Epoch 3/5\n",
            "750/750 [==============================] - 379s 505ms/step - loss: 0.1955 - accuracy: 0.9384 - val_loss: 0.1859 - val_accuracy: 0.9377\n",
            "Epoch 4/5\n",
            "750/750 [==============================] - 378s 504ms/step - loss: 0.1685 - accuracy: 0.9475 - val_loss: 0.1781 - val_accuracy: 0.9408\n",
            "Epoch 5/5\n",
            "750/750 [==============================] - 370s 493ms/step - loss: 0.1501 - accuracy: 0.9528 - val_loss: 0.1574 - val_accuracy: 0.9507\n",
            "313/313 [==============================] - 123s 393ms/step\n",
            "Epoch 1/5\n",
            "1000/1000 [==============================] - 540s 539ms/step - loss: 0.1369 - accuracy: 0.9551 - val_loss: 0.0819 - val_accuracy: 0.9728\n",
            "Epoch 2/5\n",
            "1000/1000 [==============================] - 498s 498ms/step - loss: 0.1268 - accuracy: 0.9574 - val_loss: 0.0909 - val_accuracy: 0.9655\n",
            "Epoch 3/5\n",
            "1000/1000 [==============================] - 537s 538ms/step - loss: 0.1182 - accuracy: 0.9604 - val_loss: 0.0818 - val_accuracy: 0.9724\n",
            "Epoch 4/5\n",
            "1000/1000 [==============================] - 537s 538ms/step - loss: 0.1116 - accuracy: 0.9634 - val_loss: 0.1362 - val_accuracy: 0.9520\n",
            "Epoch 5/5\n",
            "1000/1000 [==============================] - 538s 538ms/step - loss: 0.1052 - accuracy: 0.9657 - val_loss: 0.0883 - val_accuracy: 0.9676\n",
            "313/313 - 121s - loss: 0.1160 - accuracy: 0.9618 - 121s/epoch - 387ms/step\n",
            "Test accuracy with pseudo-labeling: 0.9617999792098999\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Dense, Flatten, ZeroPadding2D, Input\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras import optimizers\n",
        "\n",
        "# Load MNIST dataset\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "# Preprocess data and pad images to match VGG16 input size\n",
        "train_images = np.pad(train_images, ((0,0), (2,2), (2,2)), 'constant')  # Pad to 32x32\n",
        "test_images = np.pad(test_images, ((0,0), (2,2), (2,2)), 'constant')  # Pad to 32x32\n",
        "train_images = np.expand_dims(train_images, axis=-1).astype('float32') / 255\n",
        "test_images = np.expand_dims(test_images, axis=-1).astype('float32') / 255\n",
        "\n",
        "X_labeled, X_unlabeled, y_labeled, y_unlabeled = train_test_split(train_images, train_labels, test_size=0.5, random_state=42)\n",
        "\n",
        "# Define VGGNet model with ImageNet weights (without the top classification layers)\n",
        "input_shape = (32, 32, 1)  # Grayscale image input shape\n",
        "input_layer = Input(shape=input_shape)\n",
        "# Convert grayscale to 3 channels by stacking the same channel 3 times\n",
        "stacked_input = tf.keras.layers.Concatenate()([input_layer, input_layer, input_layer])\n",
        "\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_tensor=stacked_input)\n",
        "\n",
        "# Freeze the convolutional base\n",
        "base_model.trainable = False\n",
        "\n",
        "# Create a new model on top\n",
        "flatten_layer = Flatten()(base_model.output)\n",
        "dense_layer = Dense(128, activation='relu')(flatten_layer)\n",
        "output_layer = Dense(10, activation='softmax')(dense_layer)\n",
        "\n",
        "model = Model(inputs=input_layer, outputs=output_layer)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=optimizers.Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the initial model on labeled data\n",
        "model.fit(X_labeled, y_labeled, epochs=5, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Generate pseudo-labels for the test data using the trained model\n",
        "pseudo_labels = model.predict(test_images)\n",
        "pseudo_labels = np.argmax(pseudo_labels, axis=1)\n",
        "\n",
        "# Retrain the model on combined labeled and pseudo-labeled data\n",
        "X_combined = np.concatenate([X_labeled, test_images])\n",
        "y_combined = np.concatenate([y_labeled, pseudo_labels])\n",
        "\n",
        "model.fit(X_combined, y_combined, epochs=5, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Evaluate the model on the actual test set\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=2)\n",
        "print(f\"Test accuracy with pseudo-labeling: {test_acc}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eo94T8CYB3sv"
      },
      "source": [
        "# вывод\n",
        "Псевдомаркировка улучшила производительность модели за счет использования предсказаний модели на немеченых данных для дополнения набора меченых данных. По сравнению с моделью, обученной только на помеченных данных, точность теста с псевдомаркировкой увеличилась до 96,18 %, что свидетельствует о полезности этого метода для улучшения обобщения модели на неизвестные данные."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XkNKUgq6IH6-"
      },
      "source": [
        "# улучшение качества разметки релевантности\n",
        "Повышение точности и релевантности аннотированных или маркированных данных - необходимый шаг к улучшению качества разметки релевантности, особенно в контексте поисковых систем или поиска информации.\n",
        "Можно использовать следующие методы:\n",
        "#### Улучшенные правила аннотирования:\n",
        "Наличие четких правил гарантирует, что аннотаторы полностью понимают задачу, что позволяет получить более точные и последовательные аннотации.\n",
        "#### Меры контроля качества:\n",
        "Принятие мер контроля качества во время процесса аннотирования и использование нескольких аннотаторов для независимой маркировки одних и тех же данных и оценки их согласия помогает выявить ошибки или конфликты.\n",
        "#### Активное обучение\n",
        "Производительность модели повышается при меньших затратах на аннотирование, если использовать методы активного обучения для интеллектуального выбора образцов для аннотирования, обучения предварительной модели на небольшом наборе помеченных данных, а затем использовать эту модель для прогнозирования релевантности немеченых данных.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "ewV3JUSN_NTc",
        "outputId": "c67d6c62-8422-44fa-975a-15f62bf4c1d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "938/938 [==============================] - 369s 394ms/step\n",
            "Epoch 1/2\n",
            "753/753 [==============================] - 377s 500ms/step - loss: 0.0992 - accuracy: 0.9671 - val_loss: 0.2001 - val_accuracy: 0.9487\n",
            "Epoch 2/2\n",
            "753/753 [==============================] - 376s 499ms/step - loss: 0.0950 - accuracy: 0.9688 - val_loss: 0.1815 - val_accuracy: 0.9540\n",
            "935/935 [==============================] - 366s 391ms/step\n",
            "Epoch 1/2\n",
            "755/755 [==============================] - 379s 503ms/step - loss: 0.0948 - accuracy: 0.9688 - val_loss: 0.2836 - val_accuracy: 0.9344\n",
            "Epoch 2/2\n",
            "755/755 [==============================] - 369s 489ms/step - loss: 0.0903 - accuracy: 0.9693 - val_loss: 0.2762 - val_accuracy: 0.9392\n",
            "932/932 [==============================] - 366s 393ms/step\n",
            "Epoch 1/2\n",
            "758/758 [==============================] - 380s 501ms/step - loss: 0.0856 - accuracy: 0.9726 - val_loss: 0.3935 - val_accuracy: 0.9200\n",
            "Epoch 2/2\n",
            "758/758 [==============================] - 380s 501ms/step - loss: 0.0832 - accuracy: 0.9717 - val_loss: 0.3925 - val_accuracy: 0.9208\n",
            "929/929 [==============================] - 345s 371ms/step\n",
            "Epoch 1/2\n",
            "760/760 [==============================] - 352s 463ms/step - loss: 0.0793 - accuracy: 0.9732 - val_loss: 0.4826 - val_accuracy: 0.9102\n",
            "Epoch 2/2\n",
            "760/760 [==============================] - 364s 479ms/step - loss: 0.0778 - accuracy: 0.9741 - val_loss: 0.5039 - val_accuracy: 0.9143\n",
            "925/925 [==============================] - 346s 374ms/step\n",
            "Epoch 1/2\n",
            "763/763 [==============================] - 355s 466ms/step - loss: 0.0751 - accuracy: 0.9745 - val_loss: 0.6211 - val_accuracy: 0.8980\n",
            "Epoch 2/2\n",
            "590/763 [======================>.......] - ETA: 1:04 - loss: 0.0680 - accuracy: 0.9760"
          ]
        }
      ],
      "source": [
        "max_iterations = 10  # Set a maximum number of iterations for the active learning loop\n",
        "iteration = 0\n",
        "\n",
        "while len(X_unlabeled) > 0 and iteration < max_iterations:\n",
        "    iteration += 1\n",
        "\n",
        "    # Make predictions on the unlabeled data\n",
        "    unlabeled_predictions = model.predict(X_unlabeled)\n",
        "\n",
        "    # Calculate uncertainty using entropy\n",
        "    uncertainty = -np.sum(unlabeled_predictions * np.log(unlabeled_predictions + 1e-10), axis=1)\n",
        "\n",
        "    # Choose samples with highest uncertainty for annotation\n",
        "    num_samples_to_annotate = min(100, len(X_unlabeled))  # Annotate 100 samples or remaining if less\n",
        "    indices_to_annotate = np.argsort(uncertainty)[-num_samples_to_annotate:]\n",
        "\n",
        "    # Add the selected samples to the labeled dataset\n",
        "    pseudo_labels = np.argmax(unlabeled_predictions, axis=1)\n",
        "    X_labeled = np.concatenate((X_labeled, X_unlabeled[indices_to_annotate]))\n",
        "    y_labeled = np.concatenate((y_labeled, pseudo_labels))\n",
        "\n",
        "    # Remove the annotated samples from the unlabeled dataset\n",
        "    X_unlabeled = np.delete(X_unlabeled, indices_to_annotate, axis=0)\n",
        "\n",
        "    # Retrain the model with the updated labeled dataset\n",
        "    model.fit(X_labeled, y_labeled, epochs=2, batch_size=32, validation_split=0.2)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O7SxayGFG_jM",
        "outputId": "01eeb5a6-ef6b-4e50-b46e-0e3f272f60d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DCG for Google: 4.3009956870695225\n",
            "DCG for Yandex: 4.988198456502561\n",
            "PFound for Google: 0.5354170637728515\n",
            "PFound for Yandex: 0.5354170637728515\n",
            "t-statistic: -2.161842716615156\n",
            "p-value: 0.058890539530887895\n",
            "Fail to reject null hypothesis: No significant difference in relevance between Google and Yandex.\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Relevance scores for Google and Yandex search results\n",
        "#the relevance scores were results were achieved from http://www.analyzethis.ru/\n",
        "relevance_scores_google = [0.914, 0.983, 0.791, 0.584, 0.564, 0.769, 0.985, 0.834, 0.998, 0.428]\n",
        "relevance_scores_yandex = [0.998, 0.939, 1.000, 0.943, 0.938, 0.953, 0.719, 0.984, 0.993, 0.926]\n",
        "\n",
        "# Function to calculate DCG (Discounted Cumulative Gain)\n",
        "def calculate_dcg(relevance_scores):\n",
        "    # DCG calculation formula: DCG = rel_1 + sum(rel_i / log2(i+1)) for i in range(1, len(relevance_scores))\n",
        "    dcg = relevance_scores[0] + sum(score / np.log2(i + 2) for i, score in enumerate(relevance_scores[1:]))\n",
        "    return dcg\n",
        "\n",
        "# Function to calculate PFound\n",
        "def calculate_pfound(relevance_scores, p_break=0.15):\n",
        "    # PFound calculation logic\n",
        "    pfound = 0\n",
        "    num_relevant = sum(1 for score in relevance_scores if score > 0)  # Count the number of relevant documents\n",
        "    for i, rel_score in enumerate(relevance_scores):\n",
        "        pfound += ((1 - p_break) ** i) * (rel_score > 0)\n",
        "    pfound *= 1 / num_relevant  # Normalize by the number of relevant documents\n",
        "    return pfound\n",
        "\n",
        "# Calculate DCG for Google and Yandex\n",
        "dcg_google = calculate_dcg(relevance_scores_google)\n",
        "dcg_yandex = calculate_dcg(relevance_scores_yandex)\n",
        "\n",
        "# Calculate PFound for Google and Yandex\n",
        "pfound_google = calculate_pfound(relevance_scores_google)\n",
        "pfound_yandex = calculate_pfound(relevance_scores_yandex)\n",
        "\n",
        "# Displaying calculated search quality metrics\n",
        "print(f\"DCG for Google: {dcg_google}\")\n",
        "print(f\"DCG for Yandex: {dcg_yandex}\")\n",
        "print(f\"PFound for Google: {pfound_google}\")\n",
        "print(f\"PFound for Yandex: {pfound_yandex}\")\n",
        "\n",
        "# Calculate the t-statistic and p-value using a paired t-test\n",
        "t_statistic, p_value = ttest_rel(relevance_scores_google, relevance_scores_yandex)\n",
        "\n",
        "# Assuming alpha (significance level) is set to 0.05\n",
        "alpha = 0.05\n",
        "\n",
        "# Print the t-statistic, p-value, and decision based on significance level\n",
        "print(f\"t-statistic: {t_statistic}\")\n",
        "print(f\"p-value: {p_value}\")\n",
        "\n",
        "if p_value < alpha:\n",
        "    print(\"Reject null hypothesis: Google relevance is statistically significantly better than Yandex relevance.\")\n",
        "else:\n",
        "    print(\"Fail to reject null hypothesis: No significant difference in relevance between Google and Yandex.\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
