{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# pseudolabeling\n"
      ],
      "metadata": {
        "id": "aqeu3kpeHsTr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "klIiqwfV-ooD",
        "outputId": "e8ca69ca-c3bd-47f9-e818-0480712b7107"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n",
            "Epoch 1/5\n",
            "750/750 [==============================] - 8s 8ms/step - loss: 0.3722 - accuracy: 0.8950 - val_loss: 0.2161 - val_accuracy: 0.9373\n",
            "Epoch 2/5\n",
            "750/750 [==============================] - 5s 6ms/step - loss: 0.1777 - accuracy: 0.9491 - val_loss: 0.1566 - val_accuracy: 0.9563\n",
            "Epoch 3/5\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.1228 - accuracy: 0.9642 - val_loss: 0.1419 - val_accuracy: 0.9565\n",
            "Epoch 4/5\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.0937 - accuracy: 0.9729 - val_loss: 0.1149 - val_accuracy: 0.9648\n",
            "Epoch 5/5\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.0706 - accuracy: 0.9784 - val_loss: 0.1159 - val_accuracy: 0.9655\n",
            "313/313 [==============================] - 1s 1ms/step\n",
            "Epoch 1/5\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 0.0701 - accuracy: 0.9789 - val_loss: 0.0520 - val_accuracy: 0.9815\n",
            "Epoch 2/5\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 0.0503 - accuracy: 0.9845 - val_loss: 0.0526 - val_accuracy: 0.9806\n",
            "Epoch 3/5\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0399 - accuracy: 0.9880 - val_loss: 0.0516 - val_accuracy: 0.9805\n",
            "Epoch 4/5\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0322 - accuracy: 0.9898 - val_loss: 0.0618 - val_accuracy: 0.9787\n",
            "Epoch 5/5\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 0.0235 - accuracy: 0.9932 - val_loss: 0.0594 - val_accuracy: 0.9789\n",
            "313/313 - 1s - loss: 0.1141 - accuracy: 0.9709 - 645ms/epoch - 2ms/step\n",
            "Test accuracy with pseudo-labeling: 0.9708999991416931\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Load MNIST dataset\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "# Preprocess data and split into labeled and unlabeled data\n",
        "train_images = train_images.reshape((60000, 28, 28, 1)).astype('float32') / 255\n",
        "test_images = test_images.reshape((10000, 28, 28, 1)).astype('float32') / 255\n",
        "\n",
        "X_labeled, X_unlabeled, y_labeled, y_unlabeled = train_test_split(train_images, train_labels, test_size=0.5, random_state=42)\n",
        "\n",
        "# Define and train the initial model on labeled data\n",
        "model = Sequential([\n",
        "    Flatten(input_shape=(28, 28, 1)),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(X_labeled, y_labeled, epochs=5, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Generate pseudo-labels for the test data using the trained model\n",
        "pseudo_labels = model.predict(test_images)\n",
        "pseudo_labels = np.argmax(pseudo_labels, axis=1)\n",
        "\n",
        "# Retrain the model on combined labeled and pseudo-labeled data\n",
        "X_combined = np.concatenate([X_labeled, test_images])\n",
        "y_combined = np.concatenate([y_labeled, pseudo_labels])\n",
        "\n",
        "model.fit(X_combined, y_combined, epochs=5, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Evaluate the model on the actual test set\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=2)\n",
        "print(f\"Test accuracy with pseudo-labeling: {test_acc}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# search quality metrics"
      ],
      "metadata": {
        "id": "sOZCMWc0H4Df"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Assuming 'model' is the trained model from the previous example\n",
        "\n",
        "# Making predictions on the test set\n",
        "predictions = model.predict(test_images)\n",
        "predicted_labels = np.argmax(predictions, axis=1)\n",
        "\n",
        "# Calculating evaluation metrics\n",
        "accuracy = accuracy_score(test_labels, predicted_labels)\n",
        "precision = precision_score(test_labels, predicted_labels, average='weighted')\n",
        "recall = recall_score(test_labels, predicted_labels, average='weighted')\n",
        "f1 = f1_score(test_labels, predicted_labels, average='weighted')\n",
        "\n",
        "# Displaying evaluation metrics\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"F1 Score: {f1}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "__RFbvb8_EIl",
        "outputId": "6fc1c82a-52f0-410f-9959-bcf36cbdf80a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 3ms/step\n",
            "Accuracy: 0.9709\n",
            "Precision: 0.9711697838943246\n",
            "Recall: 0.9709\n",
            "F1 Score: 0.970900654112268\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# improving the quality of relevance markup\n",
        "Enhancing the accuracy and relevance of annotated or labeled data is a necessary step towards improving the quality of relevance markup, particularly in the context of search engines or information retrieval.\n",
        "The following techniques can be used:\n",
        "#### Improved Annotation Guidelines:\n",
        "Having clear rules ensures that annotators fully comprehend the task, which produces annotations that are more accurate and consistent.\n",
        "####  Quality Control Measures:\n",
        "Putting quality control measures in place while the annotation process is underway and Using several annotators to independently label the same data and gauge their agreement helps to spot errors or conflicts.\n",
        "#### Active Learning\n",
        "The performance of the model is enhanced with less annotation work when active learning techniques are used to intelligently choose samples for annotation, train a preliminary model on a small labeled dataset, and then leverage this model to predict the relevance of unlabeled data.\n"
      ],
      "metadata": {
        "id": "XkNKUgq6IH6-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_iterations = 10  # Set a maximum number of iterations for the active learning loop\n",
        "iteration = 0\n",
        "\n",
        "while len(X_unlabeled) > 0 and iteration < max_iterations:\n",
        "    iteration += 1\n",
        "\n",
        "    # Make predictions on the unlabeled data\n",
        "    unlabeled_predictions = model.predict(X_unlabeled)\n",
        "\n",
        "    # Calculate uncertainty using entropy\n",
        "    uncertainty = -np.sum(unlabeled_predictions * np.log(unlabeled_predictions + 1e-10), axis=1)\n",
        "\n",
        "    # Choose samples with highest uncertainty for annotation\n",
        "    num_samples_to_annotate = min(100, len(X_unlabeled))  # Annotate 100 samples or remaining if less\n",
        "    indices_to_annotate = np.argsort(uncertainty)[-num_samples_to_annotate:]\n",
        "\n",
        "    # Add the selected samples to the labeled dataset\n",
        "    pseudo_labels = np.argmax(unlabeled_predictions, axis=1)\n",
        "    X_labeled = np.concatenate((X_labeled, X_unlabeled[indices_to_annotate]))\n",
        "    y_labeled = np.concatenate((y_labeled, pseudo_labels))\n",
        "\n",
        "    # Remove the annotated samples from the unlabeled dataset\n",
        "    X_unlabeled = np.delete(X_unlabeled, indices_to_annotate, axis=0)\n",
        "\n",
        "    # Retrain the model with the updated labeled dataset\n",
        "    model.fit(X_labeled, y_labeled, epochs=2, batch_size=32, validation_split=0.2)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ewV3JUSN_NTc",
        "outputId": "bcca6e70-9aac-4eeb-eedf-9e3a1f594936"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "722/722 [==============================] - 1s 1ms/step\n",
            "Epoch 1/2\n",
            "928/928 [==============================] - 5s 5ms/step - loss: 0.0048 - accuracy: 0.9987 - val_loss: 39.2793 - val_accuracy: 0.1434\n",
            "Epoch 2/2\n",
            "928/928 [==============================] - 3s 3ms/step - loss: 0.0015 - accuracy: 0.9996 - val_loss: 40.4262 - val_accuracy: 0.1445\n",
            "719/719 [==============================] - 1s 1ms/step\n",
            "Epoch 1/2\n",
            "930/930 [==============================] - 4s 4ms/step - loss: 7.6946e-04 - accuracy: 0.9999 - val_loss: 40.8190 - val_accuracy: 0.1255\n",
            "Epoch 2/2\n",
            "930/930 [==============================] - 3s 3ms/step - loss: 2.7277e-04 - accuracy: 0.9999 - val_loss: 40.7171 - val_accuracy: 0.1245\n",
            "716/716 [==============================] - 1s 1ms/step\n",
            "Epoch 1/2\n",
            "933/933 [==============================] - 3s 3ms/step - loss: 0.0038 - accuracy: 0.9992 - val_loss: 41.8942 - val_accuracy: 0.1169\n",
            "Epoch 2/2\n",
            "933/933 [==============================] - 4s 5ms/step - loss: 0.0010 - accuracy: 0.9996 - val_loss: 44.5379 - val_accuracy: 0.1139\n",
            "713/713 [==============================] - 1s 1ms/step\n",
            "Epoch 1/2\n",
            "935/935 [==============================] - 3s 3ms/step - loss: 0.0031 - accuracy: 0.9991 - val_loss: 42.1473 - val_accuracy: 0.1076\n",
            "Epoch 2/2\n",
            "935/935 [==============================] - 3s 3ms/step - loss: 4.6605e-04 - accuracy: 0.9998 - val_loss: 42.6668 - val_accuracy: 0.1055\n",
            "710/710 [==============================] - 1s 1ms/step\n",
            "Epoch 1/2\n",
            "938/938 [==============================] - 3s 3ms/step - loss: 9.5983e-04 - accuracy: 0.9997 - val_loss: 44.0429 - val_accuracy: 0.0971\n",
            "Epoch 2/2\n",
            "938/938 [==============================] - 3s 4ms/step - loss: 0.0032 - accuracy: 0.9991 - val_loss: 44.0725 - val_accuracy: 0.0975\n",
            "707/707 [==============================] - 1s 2ms/step\n",
            "Epoch 1/2\n",
            "940/940 [==============================] - 3s 3ms/step - loss: 0.0699 - accuracy: 0.9949 - val_loss: 35.7349 - val_accuracy: 0.0968\n",
            "Epoch 2/2\n",
            "940/940 [==============================] - 3s 3ms/step - loss: 0.0320 - accuracy: 0.9967 - val_loss: 34.1239 - val_accuracy: 0.0973\n",
            "704/704 [==============================] - 1s 1ms/step\n",
            "Epoch 1/2\n",
            "943/943 [==============================] - 4s 5ms/step - loss: 0.0659 - accuracy: 0.9943 - val_loss: 30.0807 - val_accuracy: 0.0960\n",
            "Epoch 2/2\n",
            "943/943 [==============================] - 3s 3ms/step - loss: 0.0402 - accuracy: 0.9951 - val_loss: 28.9679 - val_accuracy: 0.0973\n",
            "700/700 [==============================] - 1s 1ms/step\n",
            "Epoch 1/2\n",
            "945/945 [==============================] - 3s 4ms/step - loss: 0.0782 - accuracy: 0.9922 - val_loss: 26.9889 - val_accuracy: 0.0971\n",
            "Epoch 2/2\n",
            "945/945 [==============================] - 4s 4ms/step - loss: 0.0552 - accuracy: 0.9926 - val_loss: 25.4015 - val_accuracy: 0.0963\n",
            "697/697 [==============================] - 1s 2ms/step\n",
            "Epoch 1/2\n",
            "948/948 [==============================] - 3s 3ms/step - loss: 0.0856 - accuracy: 0.9897 - val_loss: 22.6482 - val_accuracy: 0.0976\n",
            "Epoch 2/2\n",
            "948/948 [==============================] - 4s 4ms/step - loss: 0.0615 - accuracy: 0.9906 - val_loss: 21.7063 - val_accuracy: 0.0980\n",
            "694/694 [==============================] - 1s 1ms/step\n",
            "Epoch 1/2\n",
            "950/950 [==============================] - 3s 3ms/step - loss: 0.0859 - accuracy: 0.9879 - val_loss: 19.5230 - val_accuracy: 0.0993\n",
            "Epoch 2/2\n",
            "950/950 [==============================] - 3s 3ms/step - loss: 0.0605 - accuracy: 0.9896 - val_loss: 19.5551 - val_accuracy: 0.0975\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Relevance scores for Google and Yandex search results\n",
        "#the relevance scores were results were achieved from http://www.analyzethis.ru/\n",
        "relevance_scores_google = [0.914, 0.983, 0.791, 0.584, 0.564, 0.769, 0.985, 0.834, 0.998, 0.428]\n",
        "relevance_scores_yandex = [0.998, 0.939, 1.000, 0.943, 0.938, 0.953, 0.719, 0.984, 0.993, 0.926]\n",
        "\n",
        "# Function to calculate DCG (Discounted Cumulative Gain)\n",
        "def calculate_dcg(relevance_scores):\n",
        "    # DCG calculation formula: DCG = rel_1 + sum(rel_i / log2(i+1)) for i in range(1, len(relevance_scores))\n",
        "    dcg = relevance_scores[0] + sum(score / np.log2(i + 2) for i, score in enumerate(relevance_scores[1:]))\n",
        "    return dcg\n",
        "\n",
        "# Function to calculate PFound\n",
        "def calculate_pfound(relevance_scores, p_break=0.15):\n",
        "    # PFound calculation logic\n",
        "    pfound = 0\n",
        "    num_relevant = sum(1 for score in relevance_scores if score > 0)  # Count the number of relevant documents\n",
        "    for i, rel_score in enumerate(relevance_scores):\n",
        "        pfound += ((1 - p_break) ** i) * (rel_score > 0)\n",
        "    pfound *= 1 / num_relevant  # Normalize by the number of relevant documents\n",
        "    return pfound\n",
        "\n",
        "# Calculate DCG for Google and Yandex\n",
        "dcg_google = calculate_dcg(relevance_scores_google)\n",
        "dcg_yandex = calculate_dcg(relevance_scores_yandex)\n",
        "\n",
        "# Calculate PFound for Google and Yandex\n",
        "pfound_google = calculate_pfound(relevance_scores_google)\n",
        "pfound_yandex = calculate_pfound(relevance_scores_yandex)\n",
        "\n",
        "# Displaying calculated search quality metrics\n",
        "print(f\"DCG for Google: {dcg_google}\")\n",
        "print(f\"DCG for Yandex: {dcg_yandex}\")\n",
        "print(f\"PFound for Google: {pfound_google}\")\n",
        "print(f\"PFound for Yandex: {pfound_yandex}\")\n",
        "\n",
        "# Calculate the t-statistic and p-value using a paired t-test\n",
        "t_statistic, p_value = ttest_rel(relevance_scores_google, relevance_scores_yandex)\n",
        "\n",
        "# Assuming alpha (significance level) is set to 0.05\n",
        "alpha = 0.05\n",
        "\n",
        "# Print the t-statistic, p-value, and decision based on significance level\n",
        "print(f\"t-statistic: {t_statistic}\")\n",
        "print(f\"p-value: {p_value}\")\n",
        "\n",
        "if p_value < alpha:\n",
        "    print(\"Reject null hypothesis: Google relevance is statistically significantly better than Yandex relevance.\")\n",
        "else:\n",
        "    print(\"Fail to reject null hypothesis: No significant difference in relevance between Google and Yandex.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O7SxayGFG_jM",
        "outputId": "01eeb5a6-ef6b-4e50-b46e-0e3f272f60d7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DCG for Google: 4.3009956870695225\n",
            "DCG for Yandex: 4.988198456502561\n",
            "PFound for Google: 0.5354170637728515\n",
            "PFound for Yandex: 0.5354170637728515\n",
            "t-statistic: -2.161842716615156\n",
            "p-value: 0.058890539530887895\n",
            "Fail to reject null hypothesis: No significant difference in relevance between Google and Yandex.\n"
          ]
        }
      ]
    }
  ]
}